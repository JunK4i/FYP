{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8040ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>goal0</th>\n",
       "      <th>goal1</th>\n",
       "      <th>goal2</th>\n",
       "      <th>goal3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Have the butcher make them.</td>\n",
       "      <td>Buy iBooks on a Mac</td>\n",
       "      <td>Buy Stuff on Sweatcoin on iPhone or iPad</td>\n",
       "      <td>Buy Microfiber Towels</td>\n",
       "      <td>Buy Burger Patties</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avoid caffeine and alcohol the day before.</td>\n",
       "      <td>Keep Your Friends Awake for an All Nighter</td>\n",
       "      <td>Listen to Music Without Getting Caught</td>\n",
       "      <td>Feel Alert when You Wake up in the Mornings</td>\n",
       "      <td>Watch TV Without Waking Up Your Siblings</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exfoliate at least three times a week.</td>\n",
       "      <td>Get Rid of Drug Dealers in Your Neighborhood</td>\n",
       "      <td>Get Rid of and Prevent Flour Mites</td>\n",
       "      <td>Get Rid of Oak Mites</td>\n",
       "      <td>Get Rid of Blackheads and Whiteheads Using Com...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learn more than one instrument.</td>\n",
       "      <td>Be a Good Actor or Actress</td>\n",
       "      <td>Be a Good Musician</td>\n",
       "      <td>Be a Good Basketball Player</td>\n",
       "      <td>Be a Good Athlete</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get psychological help for addictive behaviors.</td>\n",
       "      <td>Fix Your Whole Life</td>\n",
       "      <td>Give Away a Puppy</td>\n",
       "      <td>Spoil Your Wife</td>\n",
       "      <td>Spoil Your Cat</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>Look for destinations and ports of call that w...</td>\n",
       "      <td>Enjoy a Trip to Nakhchivan, Azerbaijan</td>\n",
       "      <td>Enjoy a Caribbean Cruise With Children</td>\n",
       "      <td>Enjoy a Visit to a Water Park</td>\n",
       "      <td>Enjoy a Museum</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>Rent out a restaurant or an entertainment center.</td>\n",
       "      <td>Plan a Cruise</td>\n",
       "      <td>Plan a Preï¿½ï¿½ï¿½Candy Hallowee</td>\n",
       "      <td>Plan a One Direction Party</td>\n",
       "      <td>Plan a Sweet 16 Party</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>Lay out specific, relatable, achievable expect...</td>\n",
       "      <td>Gut a Pig</td>\n",
       "      <td>Kill a Stinkhorn Fungus</td>\n",
       "      <td>Gut a Squirrel</td>\n",
       "      <td>Ground Your Child</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>Bring earplugs and a sleeping mask if youï¿½ï¿...</td>\n",
       "      <td>Find Cheap Hotels in Napa Valley</td>\n",
       "      <td>Find Study Material Online</td>\n",
       "      <td>Find Festivals and Special Events in New York</td>\n",
       "      <td>Find Hostels in Europe</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>Plan activities for the visit.</td>\n",
       "      <td>Make Your Girlfriend Want to Spend Time Alone ...</td>\n",
       "      <td>Get Your Parents to Let You Date Someone</td>\n",
       "      <td>Make Your Guy Friend Want to Date You</td>\n",
       "      <td>Convince Your Parents to Let You Date</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1703 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   step  \\\n",
       "0                           Have the butcher make them.   \n",
       "1            Avoid caffeine and alcohol the day before.   \n",
       "2                Exfoliate at least three times a week.   \n",
       "3                       Learn more than one instrument.   \n",
       "4       Get psychological help for addictive behaviors.   \n",
       "...                                                 ...   \n",
       "1698  Look for destinations and ports of call that w...   \n",
       "1699  Rent out a restaurant or an entertainment center.   \n",
       "1700  Lay out specific, relatable, achievable expect...   \n",
       "1701  Bring earplugs and a sleeping mask if youï¿½ï¿...   \n",
       "1702                     Plan activities for the visit.   \n",
       "\n",
       "                                                  goal0  \\\n",
       "0                                   Buy iBooks on a Mac   \n",
       "1            Keep Your Friends Awake for an All Nighter   \n",
       "2          Get Rid of Drug Dealers in Your Neighborhood   \n",
       "3                            Be a Good Actor or Actress   \n",
       "4                                   Fix Your Whole Life   \n",
       "...                                                 ...   \n",
       "1698             Enjoy a Trip to Nakhchivan, Azerbaijan   \n",
       "1699                                      Plan a Cruise   \n",
       "1700                                          Gut a Pig   \n",
       "1701                   Find Cheap Hotels in Napa Valley   \n",
       "1702  Make Your Girlfriend Want to Spend Time Alone ...   \n",
       "\n",
       "                                         goal1  \\\n",
       "0     Buy Stuff on Sweatcoin on iPhone or iPad   \n",
       "1       Listen to Music Without Getting Caught   \n",
       "2           Get Rid of and Prevent Flour Mites   \n",
       "3                           Be a Good Musician   \n",
       "4                            Give Away a Puppy   \n",
       "...                                        ...   \n",
       "1698    Enjoy a Caribbean Cruise With Children   \n",
       "1699         Plan a Preï¿½ï¿½ï¿½Candy Hallowee   \n",
       "1700                   Kill a Stinkhorn Fungus   \n",
       "1701                Find Study Material Online   \n",
       "1702  Get Your Parents to Let You Date Someone   \n",
       "\n",
       "                                              goal2  \\\n",
       "0                             Buy Microfiber Towels   \n",
       "1       Feel Alert when You Wake up in the Mornings   \n",
       "2                              Get Rid of Oak Mites   \n",
       "3                       Be a Good Basketball Player   \n",
       "4                                   Spoil Your Wife   \n",
       "...                                             ...   \n",
       "1698                  Enjoy a Visit to a Water Park   \n",
       "1699                     Plan a One Direction Party   \n",
       "1700                                 Gut a Squirrel   \n",
       "1701  Find Festivals and Special Events in New York   \n",
       "1702          Make Your Guy Friend Want to Date You   \n",
       "\n",
       "                                                  goal3 label  \n",
       "0                                    Buy Burger Patties     D  \n",
       "1              Watch TV Without Waking Up Your Siblings     C  \n",
       "2     Get Rid of Blackheads and Whiteheads Using Com...     D  \n",
       "3                                     Be a Good Athlete     B  \n",
       "4                                        Spoil Your Cat     A  \n",
       "...                                                 ...   ...  \n",
       "1698                                     Enjoy a Museum     B  \n",
       "1699                              Plan a Sweet 16 Party     D  \n",
       "1700                                  Ground Your Child     D  \n",
       "1701                             Find Hostels in Europe     D  \n",
       "1702              Convince Your Parents to Let You Date     A  \n",
       "\n",
       "[1703 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "goal = pd.read_csv('./datasets_human_readable/goal_test.csv', encoding='ISO-8859-1')\n",
    "goal['label'] = goal['label'].map({0:'A', 1:'B',2:\"C\",3:\"D\"})\n",
    "goal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b830c",
   "metadata": {},
   "source": [
    "# Setup Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18817dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from langchain.output_parsers.fix import OutputFixingParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.llms import Ollama\n",
    "from tqdm import tqdm \n",
    "import time \n",
    "from enum import Enum\n",
    "    \n",
    "\n",
    "class ChainManager:\n",
    "    def __init__(self):\n",
    "        self.prompt = PromptTemplate.from_template(\"Tell me a short joke about {input}\")\n",
    "        self.output_parser = StrOutputParser()\n",
    "        self.df = goal\n",
    "        self.model_list = [\"llama2:text\",\"mistral\", \"orca-mini:7b\", \"qwen:7b\"]\n",
    "        self.logs = []\n",
    "        \n",
    "    def run_single_query(self, inputs, model_name, verbose, output_file_name=\"\"):\n",
    "        full_prompt = self.prompt.format(step=inputs[\"step\"], goal0=inputs[\"goal0\"],goal1=inputs[\"goal1\"],goal2=inputs[\"goal2\"], goal3=inputs[\"goal3\"])\n",
    "        if verbose:\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "            print(f\"model_name: {model_name}\")\n",
    "            print(f\"prompt: {full_prompt}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(\"----------------------------------------------------------------------\")\n",
    "            self.write_string_to_buffer(f\"model_name: {model_name}\")\n",
    "            self.write_string_to_buffer(f\"prompt: {full_prompt}\")\n",
    "                \n",
    "        chain = (\n",
    "            self.prompt\n",
    "            | Ollama(model=model_name)\n",
    "            | self.output_parser)\n",
    "\n",
    "        chain_of_thought = chain.invoke(inputs)\n",
    "        classifier_output = self.run_retry_classifier(chain_of_thought, 3, verbose)\n",
    "        final_answer = classifier_output[0]\n",
    "        num_retries = classifier_output[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Classifier finished...\\n\")\n",
    "            print(f\"chain_of_thought: {chain_of_thought}\\n\")\n",
    "            print(f\"final_answer: {final_answer}\")\n",
    "            print(f\"correct_answer: {inputs['label']}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(f\"classifier finished....\\n\")\n",
    "            self.write_string_to_buffer(f\"chain_of_thought: {chain_of_thought}\\n\")\n",
    "            self.write_string_to_buffer(f\"final_answer: {final_answer}\")\n",
    "            self.write_string_to_buffer(f\"correct_answer: {inputs['label']}\")\n",
    "            self.write_buffer_to_file(output_file_name)\n",
    "        return classifier_output\n",
    "    \n",
    "    def run_batch_query(self, verbose, batch_size, output_file_name=\"\"):\n",
    "        self.df = self.df.iloc[0:0+batch_size].copy()\n",
    "        input_list = self.df.to_dict('records')\n",
    "        if output_file_name != \"\":\n",
    "            self.clear_existing_file(output_file_name)\n",
    "        for model_name in self.model_list:\n",
    "            results = []\n",
    "            num_retries = []\n",
    "            for item in tqdm(input_list, desc=\"Processing queries\"):\n",
    "#                     result = self.run_single_query(item, model_name, verbose, output_file_name) \n",
    "                    result = self.run_single_self_review(item, model_name, verbose, output_file_name) \n",
    "                    results.append(result[0])\n",
    "                    num_retries.append(result[1])\n",
    "                    \n",
    "            self.df[model_name] = results \n",
    "            self.df[model_name+\"_retries\"] = num_retries \n",
    "\n",
    "    def evaluate_order(self):\n",
    "        for model_name in self.model_list:\n",
    "            binary_results = self.df[model_name].str.strip().str[0]\n",
    "            correct_predictions = (self.df['label'] == binary_results).sum()\n",
    "            total_predictions = len(self.df)\n",
    "            accuracy = correct_predictions / total_predictions\n",
    "            print(f\"{model_name}: {accuracy}\")\n",
    "        \n",
    "    \n",
    "    def verify_output(self, mcq_choice):\n",
    "        if mcq_choice == \"A\" or mcq_choice == \"B\" or mcq_choice == \"C\" or mcq_choice == \"D\":\n",
    "            return True\n",
    "        else: \n",
    "            return False        \n",
    "        \n",
    "    def run_classifier(self, initial_answer):\n",
    "        \n",
    "        classifier_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        You are recieving an explanation from a language model about its choice for an mcq question.\n",
    "        You are a mcq classifier. You are to select the answer based on the explanation provided.\n",
    "        You are not to explain or mention anything other than provide the answer for the mcq.\n",
    "        If not enough information, randomly select one.\n",
    "        Please do not give me anything other than one letter thanks!\n",
    "        MCQ Choices: A, B, C, D            \n",
    "\n",
    "        Explanation: {initial_answer}\n",
    "        Answer:\n",
    "        \"\"\")\n",
    "        \n",
    "        chain = (\n",
    "            classifier_prompt\n",
    "            | Ollama(model=\"mistral\")\n",
    "            | self.output_parser\n",
    "            \n",
    "        )\n",
    "        output = chain.invoke({\"initial_answer\": initial_answer})\n",
    "        return output\n",
    "    \n",
    "    def run_retry_classifier(self, initial_answer, max_tries, verbose, output_file_name=\"\"):\n",
    "        if verbose:\n",
    "            print(\"Running classifier....\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(\"Running classifier....\")\n",
    "\n",
    "        mcq_choice = 0\n",
    "        for i in range(max_tries):\n",
    "            classifier_output = self.run_classifier(initial_answer)\n",
    "            if verbose:\n",
    "                print(f\"retry_classifier_{i+1}: {classifier_output}\")\n",
    "            else:\n",
    "                self.write_string_to_buffer(f\"retry_classifier_{i+1}: {classifier_output}\")\n",
    "            mcq_choice = classifier_output.strip()[0].upper()\n",
    "            if self.verify_output(mcq_choice):\n",
    "                return (mcq_choice, i+1)\n",
    "        return (mcq_choice, max_tries)\n",
    "    \n",
    "    def run_self_review(self, question, answer, model):\n",
    "        info_retrieval_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        Question: {question}\n",
    "        \n",
    "        Previous answer: {answer}\n",
    "        \n",
    "        Review your previous answer and find problems with your answer.\n",
    "        \"\"\")\n",
    "    \n",
    "        chain = (\n",
    "            info_retrieval_prompt\n",
    "            | model\n",
    "            | self.output_parser\n",
    "            \n",
    "        )\n",
    "        output = chain.invoke({\"question\": question, \"answer\": answer})\n",
    "        return output\n",
    "        \n",
    "       \n",
    "    def run_single_self_review(self, inputs, model_name, verbose, output_file_name=\"\"):\n",
    "        \n",
    "        llm_model = Ollama(model=model_name)\n",
    "        \n",
    "        full_prompt = self.prompt.format(step=inputs[\"step\"], goal0=inputs[\"goal0\"],goal1=inputs[\"goal1\"],goal2=inputs[\"goal2\"], goal3=inputs[\"goal3\"])\n",
    "        if verbose:\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "            print(f\"model_name: {model_name}\")\n",
    "            print(f\"prompt: {full_prompt}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(\"----------------------------------------------------------------------\")\n",
    "            self.write_string_to_buffer(f\"model_name: {model_name}\")\n",
    "            self.write_string_to_buffer(f\"prompt: {full_prompt}\")\n",
    "                        \n",
    "        chain = (\n",
    "            self.prompt\n",
    "            | llm_model\n",
    "            | self.output_parser)\n",
    "\n",
    "        chain_of_thought = chain.invoke(inputs)\n",
    "        \n",
    "        critique = self.run_self_review(full_prompt, chain_of_thought, llm_model)\n",
    "        \n",
    "        final_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        Question: {question}\n",
    "                \n",
    "        Critique: {critique}\n",
    "        \n",
    "        Based on the problems you found, improve your answer.\n",
    "        \"\"\")\n",
    "        \n",
    "        final_chain = (\n",
    "            final_prompt\n",
    "            | llm_model\n",
    "            | self.output_parser\n",
    "        )\n",
    "        \n",
    "        improved_answer = final_chain.invoke({\"question\": full_prompt, \"answer\": chain_of_thought, \"critique\": critique})\n",
    "        \n",
    "        classifier_output = self.run_retry_classifier(improved_answer, 3, verbose)\n",
    "        final_answer = classifier_output[0]\n",
    "        num_retries = classifier_output[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Classifier finished...\\n\")\n",
    "            print(f\"chain_of_thought: {chain_of_thought}\\n\")\n",
    "            print(f\"critique: {critique}\\n\")\n",
    "            print(f\"improved_answer: {improved_answer}\")\n",
    "            print(f\"final_answer: {final_answer}\")\n",
    "            print(f\"correct_answer: {inputs['label']}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(f\"classifier finished....\\n\")\n",
    "            self.write_string_to_buffer(f\"chain_of_thought: {chain_of_thought}\")\n",
    "            self.write_string_to_buffer(f\"critique: {critique}\\n\")\n",
    "            self.write_string_to_buffer(f\"improved_answer: {improved_answer}\\n\")\n",
    "            self.write_string_to_buffer(f\"final_answer: {final_answer}\")\n",
    "            self.write_string_to_buffer(f\"correct_answer: {inputs['label']}\")\n",
    "            self.write_buffer_to_file(output_file_name)\n",
    "        return  classifier_output\n",
    "    \n",
    "    def write_string_to_buffer(self, input_string):\n",
    "        self.logs.append(input_string)\n",
    "    \n",
    "    def write_buffer_to_file(self, filename):\n",
    "        with open(filename, 'a') as file:\n",
    "            for log in self.logs:\n",
    "                file.write(\"\\n\"+log)\n",
    "            self.logs = []\n",
    "        \n",
    "    def clear_existing_file(self, filename):\n",
    "         with open(filename, 'w') as file:\n",
    "            file.write(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c43b46",
   "metadata": {},
   "source": [
    "### Single Prompt + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baab3ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|█████████████████████| 350/350 [1:13:58<00:00, 12.68s/it]\n",
      "Processing queries: 100%|███████████████████████| 350/350 [26:30<00:00,  4.54s/it]\n",
      "Processing queries: 100%|█████████████████████| 350/350 [1:01:02<00:00, 10.46s/it]\n",
      "Processing queries: 100%|█████████████████████| 350/350 [1:27:34<00:00, 15.01s/it]\n"
     ]
    }
   ],
   "source": [
    "simple_QA_chain = ChainManager()\n",
    "\n",
    "simple_QA_chain.prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are answering a multiple choice question.\n",
    "You are given a step that is included in a one of the four tutorial choices. \n",
    "Given four choices, you are to determine which tutorial this step belongs to.\n",
    "Step: {step}\n",
    "MCQ:\n",
    "A: {goal0}\n",
    "B: {goal1}\n",
    "C: {goal2}\n",
    "D: {goal3}\n",
    "\"\"\")\n",
    "\n",
    "simple_QA_chain.run_batch_query(False, 350, \"/Users/kohjunkai/Desktop/goal_simple_QA.txt\")\n",
    "simple_QA_chain.df.to_csv('/Users/kohjunkai/Desktop/goal_simple_QA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf78eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama2: 0.5857142857142857\n",
      "mistral: 0.6285714285714286\n",
      "orca-mini:7b: 0.52\n",
      "qwen:7b: 0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "simple_QA_chain.evaluate_order()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad06ff4",
   "metadata": {},
   "source": [
    "### Chain of thought  + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "221e3fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|█████████████████████| 350/350 [1:29:22<00:00, 15.32s/it]\n",
      "Processing queries: 100%|███████████████████████| 350/350 [44:56<00:00,  7.70s/it]\n",
      "Processing queries: 100%|█████████████████████| 350/350 [1:19:02<00:00, 13.55s/it]\n",
      "Processing queries: 100%|█████████████████████| 350/350 [1:40:59<00:00, 17.31s/it]\n"
     ]
    }
   ],
   "source": [
    "chain = ChainManager()\n",
    "\n",
    "chain.prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are answering a multiple choice question. \n",
    "You are given a step that is included in a one of the four tutorial choices. \n",
    "Given four choices, you are to determine which tutorial this step belongs to.\n",
    "Step: {step}\n",
    "MCQ:\n",
    "A: {goal0}\n",
    "B: {goal1}\n",
    "C: {goal2}\n",
    "D: {goal3}\n",
    "You are to provide a clear explanation for your choice..\n",
    "At the end of your explanation, explicitly state which tutorial the step belongs to.\n",
    "\"\"\")\n",
    "\n",
    "chain.run_batch_query(False, 350, \"/Users/kohjunkai/Desktop/goal_COT.txt\")\n",
    "chain.df.to_csv('/Users/kohjunkai/Desktop/goal_COT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.df.to_csv('order_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63eea9",
   "metadata": {},
   "source": [
    "### Self Critique + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b096ad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|█████████████████████| 200/200 [1:39:34<00:00, 29.87s/it]\n",
      "Processing queries: 100%|█████████████████████| 200/200 [1:22:05<00:00, 24.63s/it]\n",
      "Processing queries: 100%|█████████████████████| 200/200 [1:15:58<00:00, 22.79s/it]\n",
      "Processing queries: 100%|█████████████████████| 200/200 [1:29:12<00:00, 26.76s/it]\n"
     ]
    }
   ],
   "source": [
    "critique_chain = ChainManager()\n",
    "\n",
    "critique_chain.prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are answering a multiple choice question. \n",
    "You are given a step that is included in a one of the four tutorial choices. \n",
    "Given four choices, you are to determine which tutorial this step belongs to.\n",
    "Step: {step}\n",
    "MCQ:\n",
    "A: {goal0}\n",
    "B: {goal1}\n",
    "C: {goal2}\n",
    "D: {goal3}\n",
    "You are to provide a clear explanation for your choice..\n",
    "At the end of your explanation, explicitly state which tutorial the step belongs to.\n",
    "\"\"\")\n",
    "\n",
    "critique_chain.run_batch_query(False,200, \"/Users/kohjunkai/Desktop/goal_self_critique.txt\")\n",
    "critique_chain.df.to_csv('/Users/kohjunkai/Desktop/goal_self_critique.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f7b138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama2: 0.6\n",
      "mistral: 0.5\n",
      "orca-mini:7b: 0.4\n",
      "qwen:7b: 0.5\n"
     ]
    }
   ],
   "source": [
    "info_gen_chain.evaluate_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a71df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8dd101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>step0</th>\n",
       "      <th>step1</th>\n",
       "      <th>step2</th>\n",
       "      <th>step3</th>\n",
       "      <th>label</th>\n",
       "      <th>Human Evaluation</th>\n",
       "      <th>Noteworthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solve an Algebraic Expression</td>\n",
       "      <td>Learn how to observe your own thoughts.</td>\n",
       "      <td>Perform a waste audit.</td>\n",
       "      <td>Know the order of operations.</td>\n",
       "      <td>Find your loan information.</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fake Food Poisoning</td>\n",
       "      <td>Go to a historical preservation.</td>\n",
       "      <td>Place time restrictions on impulsive thoughts.</td>\n",
       "      <td>Decide on the background or the foreground.</td>\n",
       "      <td>Invent a dicey dining situation.</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prevent Toxic Shock Syndrome</td>\n",
       "      <td>Draw lines at the bottom loop and then they wi...</td>\n",
       "      <td>Follow instructions carefully when using vagin...</td>\n",
       "      <td>Spot test your blood on a dirty shirt to see h...</td>\n",
       "      <td>Place the wine glass upside down on a soft tow...</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Report a School for Discriminatory Discipline</td>\n",
       "      <td>Consider filing an institutional grievance.</td>\n",
       "      <td>Double check all payment amounts.</td>\n",
       "      <td>Copy and mail your form.</td>\n",
       "      <td>Identify a suspected fraudulent mortgage.</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List for Sale by Owner Using MLS Listing</td>\n",
       "      <td>Learning about more than.</td>\n",
       "      <td>Know what a payment gateway is.</td>\n",
       "      <td>Know what a finance charge is.</td>\n",
       "      <td>Know what the Multiple Listing Service system is.</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>Figure Out a Song by Ear</td>\n",
       "      <td>Identify the tonic (I) chord.</td>\n",
       "      <td>Use the basic accounting equation to make a ba...</td>\n",
       "      <td>Look at day two so the amount that starts doub...</td>\n",
       "      <td>Upload a video of your project if you have one.</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>Stay Focused on God</td>\n",
       "      <td>Look after yourself physically.</td>\n",
       "      <td>Discourage your friend from contacting the ex.</td>\n",
       "      <td>Have and seek respect.</td>\n",
       "      <td>Make time for your faith every day.</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>Save Money for Something Big As a Teen</td>\n",
       "      <td>Do some research on whatever country you are i...</td>\n",
       "      <td>Do an internship with Homeland Security if you...</td>\n",
       "      <td>Look for work in mental health clinics and psy...</td>\n",
       "      <td>Get a job (if you are old enough).</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>Move to Switzerland</td>\n",
       "      <td>Ask veterans you know to share their experiences.</td>\n",
       "      <td>Take on shopping at the famous Union Station.</td>\n",
       "      <td>Convert your currency into Swiss francs.</td>\n",
       "      <td>Determine your characterï¿½ï¿½ï¿½s ï¿½ï¿½ï¿½wo...</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>Get Rid of Odorous Ants</td>\n",
       "      <td>Make a protein-based trap.</td>\n",
       "      <td>Build a model house or a dollhouse.</td>\n",
       "      <td>Purchase a latch hooked rug kit.</td>\n",
       "      <td>Put up some Rock posters.</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               goal  \\\n",
       "0                     Solve an Algebraic Expression   \n",
       "1                               Fake Food Poisoning   \n",
       "2                      Prevent Toxic Shock Syndrome   \n",
       "3     Report a School for Discriminatory Discipline   \n",
       "4          List for Sale by Owner Using MLS Listing   \n",
       "...                                             ...   \n",
       "2245                       Figure Out a Song by Ear   \n",
       "2246                            Stay Focused on God   \n",
       "2247         Save Money for Something Big As a Teen   \n",
       "2248                            Move to Switzerland   \n",
       "2249                        Get Rid of Odorous Ants   \n",
       "\n",
       "                                                  step0  \\\n",
       "0               Learn how to observe your own thoughts.   \n",
       "1                      Go to a historical preservation.   \n",
       "2     Draw lines at the bottom loop and then they wi...   \n",
       "3           Consider filing an institutional grievance.   \n",
       "4                             Learning about more than.   \n",
       "...                                                 ...   \n",
       "2245                      Identify the tonic (I) chord.   \n",
       "2246                    Look after yourself physically.   \n",
       "2247  Do some research on whatever country you are i...   \n",
       "2248  Ask veterans you know to share their experiences.   \n",
       "2249                         Make a protein-based trap.   \n",
       "\n",
       "                                                  step1  \\\n",
       "0                                Perform a waste audit.   \n",
       "1        Place time restrictions on impulsive thoughts.   \n",
       "2     Follow instructions carefully when using vagin...   \n",
       "3                     Double check all payment amounts.   \n",
       "4                       Know what a payment gateway is.   \n",
       "...                                                 ...   \n",
       "2245  Use the basic accounting equation to make a ba...   \n",
       "2246     Discourage your friend from contacting the ex.   \n",
       "2247  Do an internship with Homeland Security if you...   \n",
       "2248      Take on shopping at the famous Union Station.   \n",
       "2249                Build a model house or a dollhouse.   \n",
       "\n",
       "                                                  step2  \\\n",
       "0                         Know the order of operations.   \n",
       "1           Decide on the background or the foreground.   \n",
       "2     Spot test your blood on a dirty shirt to see h...   \n",
       "3                              Copy and mail your form.   \n",
       "4                        Know what a finance charge is.   \n",
       "...                                                 ...   \n",
       "2245  Look at day two so the amount that starts doub...   \n",
       "2246                             Have and seek respect.   \n",
       "2247  Look for work in mental health clinics and psy...   \n",
       "2248           Convert your currency into Swiss francs.   \n",
       "2249                   Purchase a latch hooked rug kit.   \n",
       "\n",
       "                                                  step3 label  \\\n",
       "0                           Find your loan information.     C   \n",
       "1                      Invent a dicey dining situation.     D   \n",
       "2     Place the wine glass upside down on a soft tow...     B   \n",
       "3             Identify a suspected fraudulent mortgage.     A   \n",
       "4     Know what the Multiple Listing Service system is.     D   \n",
       "...                                                 ...   ...   \n",
       "2245    Upload a video of your project if you have one.     A   \n",
       "2246                Make time for your faith every day.     D   \n",
       "2247                 Get a job (if you are old enough).     D   \n",
       "2248  Determine your characterï¿½ï¿½ï¿½s ï¿½ï¿½ï¿½wo...     C   \n",
       "2249                          Put up some Rock posters.     A   \n",
       "\n",
       "     Human Evaluation Noteworthy  \n",
       "0                   C        NaN  \n",
       "1                   D        NaN  \n",
       "2                   C        NaN  \n",
       "3                   A        NaN  \n",
       "4                   D        NaN  \n",
       "...               ...        ...  \n",
       "2245              NaN        NaN  \n",
       "2246              NaN        NaN  \n",
       "2247              NaN        NaN  \n",
       "2248              NaN        NaN  \n",
       "2249              NaN        NaN  \n",
       "\n",
       "[2250 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "step = pd.read_csv('./datasets_human_readable/step_test.csv', encoding='ISO-8859-1')\n",
    "step['label'] = step['label'].map({0:'A', 1:'B',2:\"C\",3:\"D\"})\n",
    "step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b830c",
   "metadata": {},
   "source": [
    "# Setup Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18817dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from langchain.output_parsers.fix import OutputFixingParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.llms import Ollama\n",
    "from tqdm import tqdm \n",
    "import time \n",
    "from enum import Enum\n",
    "from langchain.globals import set_verbose\n",
    "\n",
    "set_verbose(True)\n",
    "    \n",
    "\n",
    "class ChainManager:\n",
    "    def __init__(self):\n",
    "        self.prompt = PromptTemplate.from_template(\"Tell me a short joke about {input}\")\n",
    "        self.output_parser = StrOutputParser()\n",
    "        self.df = step\n",
    "#         self.model_list = [\"mistral\"]\n",
    "        self.model_list = [\"llama2\",\"mistral\", \"orca-mini:7b\", \"qwen:7b\"]\n",
    "        self.logs = []\n",
    "\n",
    "    def run_without_classifier (self, inputs, model_name, verbose, output_file_name=\"\"):\n",
    "        chain = (\n",
    "            self.prompt\n",
    "            | Ollama(model=model_name)\n",
    "            | self.output_parser)\n",
    "        output = chain.invoke(inputs)\n",
    "        full_prompt = self.prompt.format(goal=inputs[\"goal\"], step0=inputs[\"step0\"],step1=inputs[\"step1\"],step2=inputs[\"step2\"], step3=inputs[\"step3\"])\n",
    "\n",
    "        if verbose:\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "            print(f\"model_name: {model_name}\")\n",
    "            print(f\"prompt: {full_prompt}\")\n",
    "            print(f\"output: {output}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(\"----------------------------------------------------------------------\")\n",
    "            self.write_string_to_buffer(f\"model_name: {model_name}\")\n",
    "            self.write_string_to_buffer(f\"prompt: {full_prompt}\")\n",
    "            self.write_string_to_buffer(f\"output: {output}\")\n",
    "            \n",
    "        return (output.strip()[0].upper(), 1)\n",
    "\n",
    "    def run_single_query(self, inputs, model_name, verbose, output_file_name=\"\"):\n",
    "        full_prompt = self.prompt.format(goal=inputs[\"goal\"], step0=inputs[\"step0\"],step1=inputs[\"step1\"],step2=inputs[\"step2\"], step3=inputs[\"step3\"])\n",
    "        if verbose:\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "            print(f\"model_name: {model_name}\")\n",
    "            print(f\"prompt: {full_prompt}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(\"----------------------------------------------------------------------\")\n",
    "            self.write_string_to_buffer(f\"model_name: {model_name}\")\n",
    "            self.write_string_to_buffer(f\"prompt: {full_prompt}\")\n",
    "        \n",
    "#         generated_tutorial = self.run_information_retrieval(inputs)\n",
    "        \n",
    "        chain = (\n",
    "            self.prompt\n",
    "            | Ollama(model=model_name)\n",
    "            | self.output_parser)\n",
    "\n",
    "        chain_of_thought = chain.invoke(inputs)\n",
    "        classifier_output = self.run_retry_classifier(chain_of_thought, 3, verbose)\n",
    "        final_answer = classifier_output[0]\n",
    "        num_retries = classifier_output[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Classifier finished...\\n\")\n",
    "            print(f\"chain_of_thought: {chain_of_thought}\\n\")\n",
    "            print(f\"final_answer: {final_answer}\")\n",
    "            print(f\"correct_answer: {inputs['label']}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(f\"classifier finished....\\n\")\n",
    "            self.write_string_to_buffer(f\"chain_of_thought: {chain_of_thought}\\n\")\n",
    "            self.write_string_to_buffer(f\"final_answer: {final_answer}\")\n",
    "            self.write_string_to_buffer(f\"correct_answer: {inputs['label']}\")\n",
    "            self.write_buffer_to_file(output_file_name)\n",
    "        return classifier_output\n",
    "    \n",
    "    def run_batch_query(self, verbose, batch_size, output_file_name=\"\"):\n",
    "        self.df = self.df.iloc[0:batch_size].copy()\n",
    "        input_list = self.df.to_dict('records')\n",
    "        if output_file_name != \"\":\n",
    "            self.clear_existing_file(output_file_name)\n",
    "        for model_name in self.model_list:\n",
    "            results = []\n",
    "            num_retries = []\n",
    "            for item in tqdm(input_list, desc=\"Processing queries\"):\n",
    "#                     result = self.run_single_query(item, model_name, verbose, output_file_name) \n",
    "                    result = self.run_single_self_review(item, model_name, verbose, output_file_name) \n",
    "#                     result = self.run_without_classifier(item, model_name, verbose, output_file_name) \n",
    "                    results.append(result[0])\n",
    "                    num_retries.append(result[1])\n",
    "                    \n",
    "            self.df[model_name] = results \n",
    "            self.df[model_name+\"_retries\"] = num_retries \n",
    "\n",
    "    def evaluate_order(self):\n",
    "        for model_name in self.model_list:\n",
    "            binary_results = self.df[model_name].str.strip().str[0]\n",
    "            correct_predictions = (self.df['label'] == binary_results).sum()\n",
    "            total_predictions = len(self.df)\n",
    "            accuracy = correct_predictions / total_predictions\n",
    "            print(f\"{model_name}: {accuracy}\")\n",
    "        \n",
    "    \n",
    "    def verify_output(self, mcq_choice):\n",
    "        if mcq_choice == \"A\" or mcq_choice == \"B\" or mcq_choice == \"C\" or mcq_choice == \"D\":\n",
    "            return True\n",
    "        else: \n",
    "            return False        \n",
    "        \n",
    "    def run_classifier(self, initial_answer):\n",
    "        \n",
    "        classifier_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        You are recieving an explanation from a language model about its choice for an mcq question.\n",
    "        You are a mcq classifier. You are to select the answer based on the explanation provided.\n",
    "        You are not to explain or mention anything other than provide the answer for the mcq.\n",
    "        If not enough information, randomly select one.\n",
    "        Please do not give me anything other than one letter thanks!\n",
    "        MCQ Choices: A, B, C, D            \n",
    "\n",
    "        Explanation: {initial_answer}\n",
    "        Answer:\n",
    "        \"\"\")\n",
    "        \n",
    "        chain = (\n",
    "            classifier_prompt\n",
    "            | Ollama(model=\"mistral\")\n",
    "            | self.output_parser\n",
    "            \n",
    "        )\n",
    "        output = chain.invoke({\"initial_answer\": initial_answer})\n",
    "        return output\n",
    "    \n",
    "    def run_retry_classifier(self, initial_answer, max_tries, verbose, output_file_name=\"\"):\n",
    "        if verbose:\n",
    "            print(\"Running classifier....\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(\"Running classifier....\")\n",
    "\n",
    "        mcq_choice = 0\n",
    "        for i in range(max_tries):\n",
    "            classifier_output = self.run_classifier(initial_answer)\n",
    "            if verbose:\n",
    "                print(f\"retry_classifier_{i+1}: {classifier_output}\")\n",
    "            else:\n",
    "                self.write_string_to_buffer(f\"retry_classifier_{i+1}: {classifier_output}\")\n",
    "            mcq_choice = classifier_output.strip()[0].upper()\n",
    "            if self.verify_output(mcq_choice):\n",
    "                return (mcq_choice, i+1)\n",
    "        return (mcq_choice, max_tries)\n",
    "    \n",
    "    def run_self_review(self, question, answer, model):\n",
    "        info_retrieval_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        Question: {question}\n",
    "        \n",
    "        Previous answer: {answer}\n",
    "        \n",
    "        Review your previous answer and find problems with your answer.\n",
    "        \"\"\")\n",
    "    \n",
    "        chain = (\n",
    "            info_retrieval_prompt\n",
    "            | model\n",
    "            | self.output_parser\n",
    "            \n",
    "        )\n",
    "        output = chain.invoke({\"question\": question, \"answer\": answer})\n",
    "        return output\n",
    "        \n",
    "    def run_single_self_review(self, inputs, model_name, verbose, output_file_name=\"\"):\n",
    "        \n",
    "        llm_model = Ollama(model=model_name)\n",
    "        \n",
    "        full_prompt = self.prompt.format(goal=inputs[\"goal\"], step0=inputs[\"step0\"],step1=inputs[\"step1\"])\n",
    "        if verbose:\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "            print(f\"model_name: {model_name}\")\n",
    "            print(f\"prompt: {full_prompt}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(\"----------------------------------------------------------------------\")\n",
    "            self.write_string_to_buffer(f\"model_name: {model_name}\")\n",
    "            self.write_string_to_buffer(f\"prompt: {full_prompt}\")\n",
    "                        \n",
    "        chain = (\n",
    "            self.prompt\n",
    "            | llm_model\n",
    "            | self.output_parser)\n",
    "\n",
    "        chain_of_thought = chain.invoke(inputs)\n",
    "        \n",
    "        critique = self.run_self_review(full_prompt, chain_of_thought, llm_model)\n",
    "        \n",
    "        final_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        Question: {question}\n",
    "                \n",
    "        Critique: {critique}\n",
    "        \n",
    "        Based on the problems you found, improve your answer.\n",
    "        \"\"\")\n",
    "        \n",
    "        final_chain = (\n",
    "            final_prompt\n",
    "            | llm_model\n",
    "            | self.output_parser\n",
    "        )\n",
    "        \n",
    "        improved_answer = final_chain.invoke({\"question\": full_prompt, \"answer\": chain_of_thought, \"critique\": critique})\n",
    "        \n",
    "        classifier_output = self.run_retry_classifier(improved_answer, 3, verbose)\n",
    "        final_answer = classifier_output[0]\n",
    "        num_retries = classifier_output[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Classifier finished...\\n\")\n",
    "            print(f\"chain_of_thought: {chain_of_thought}\\n\")\n",
    "            print(f\"critique: {critique}\\n\")\n",
    "            print(f\"improved_answer: {improved_answer}\")\n",
    "            print(f\"final_answer: {final_answer}\")\n",
    "            print(f\"correct_answer: {inputs['label']}\")\n",
    "        else:\n",
    "            self.write_string_to_buffer(f\"classifier finished....\\n\")\n",
    "            self.write_string_to_buffer(f\"chain_of_thought: {chain_of_thought}\")\n",
    "            self.write_string_to_buffer(f\"critique: {critique}\\n\")\n",
    "            self.write_string_to_buffer(f\"improved_answer: {improved_answer}\\n\")\n",
    "            self.write_string_to_buffer(f\"final_answer: {final_answer}\")\n",
    "            self.write_string_to_buffer(f\"correct_answer: {inputs['label']}\")\n",
    "            self.write_buffer_to_file(output_file_name)\n",
    "        return  classifier_output\n",
    "    \n",
    "\n",
    "    def write_string_to_buffer(self, input_string):\n",
    "        self.logs.append(input_string)\n",
    "    \n",
    "    def write_buffer_to_file(self, filename):\n",
    "        with open(filename, 'a') as file:\n",
    "            for log in self.logs:\n",
    "                file.write(\"\\n\"+log)\n",
    "            self.logs = []\n",
    "        \n",
    "    def clear_existing_file(self, filename):\n",
    "         with open(filename, 'w') as file:\n",
    "            file.write(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c43b46",
   "metadata": {},
   "source": [
    "### Single Prompt + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baab3ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|█████████████████████| 350/350 [1:22:02<00:00, 14.07s/it]\n",
      "Processing queries: 100%|███████████████████████| 350/350 [31:38<00:00,  5.43s/it]\n",
      "Processing queries: 100%|█████████████████████| 350/350 [1:03:01<00:00, 10.80s/it]\n",
      "Processing queries: 100%|█████████████████████| 350/350 [1:26:18<00:00, 14.79s/it]\n"
     ]
    }
   ],
   "source": [
    "simple_QA_chain = ChainManager()\n",
    "\n",
    "simple_QA_chain.prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are answering a multiple choice question.\n",
    "Given four choices, you are to determine which step belongs in the tutorial of how to {goal}\n",
    "MCQ:\n",
    "A: {step0}\n",
    "B: {step1}\n",
    "C: {step2}\n",
    "D: {step3}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "simple_QA_chain.run_batch_query(False, 350, \"/Users/kohjunkai/Desktop/step_simple_QA.txt\")\n",
    "simple_QA_chain.df.to_csv('/Users/kohjunkai/Desktop/step_simple_QA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d49f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries:   5%|█▏                      | 1/20 [00:06<01:59,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "model_name: llama2:text\n",
      "prompt: \n",
      "You are answering a multiple choice question.\n",
      "Given four choices, you are to determine which step belongs in the tutorial.\n",
      "\n",
      "For example:\n",
      "Determine which step belongs in the tutorial of how to Send Money from India\n",
      "A: Have your forms reviewed if possible.\n",
      "B: Choose how the funds will be distributed.\n",
      "C: Develop a personal tagline.\n",
      "D: Wash your hair with an antifungal shampoo.\n",
      "\n",
      "Answer: B\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Get 1k Followers on Instagram\n",
      "A: Add a relevant, informative bio.\n",
      "B: Find strength in numbers.\n",
      "C: Understand how restrictive modifiers work.\n",
      "D: Write the two-column proof as an outline.\n",
      "\n",
      "Answer: A\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Solve an Algebraic Expression\n",
      "MCQ:\n",
      "A: Learn how to observe your own thoughts.\n",
      "B: Perform a waste audit.\n",
      "C: Know the order of operations.\n",
      "D: Find your loan information.\n",
      "\n",
      "Answer:\n",
      "\n",
      "output: D\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Get Started with Blogging\n",
      "MCQ:\n",
      "A: Create a personalized URL.\n",
      "B: Consider your audience.\n",
      "C: Choose the right blogging platform.\n",
      "D: Write for a specific person you know.\n",
      "\n",
      "Answer: A\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Teach Kids About Money\n",
      "MCQ:\n",
      "A: Be aware of their learning styles and needs.\n",
      "B: Understand your budget, spending habits and debt-to-income ratio.\n",
      "C: Determine a savings goal for the year.\n",
      "D: Have them research stocks and bonds online.\n",
      "\n",
      "Answer: B\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing queries:  10%|██▍                     | 2/20 [00:08<01:10,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "model_name: llama2:text\n",
      "prompt: \n",
      "You are answering a multiple choice question.\n",
      "Given four choices, you are to determine which step belongs in the tutorial.\n",
      "\n",
      "For example:\n",
      "Determine which step belongs in the tutorial of how to Send Money from India\n",
      "A: Have your forms reviewed if possible.\n",
      "B: Choose how the funds will be distributed.\n",
      "C: Develop a personal tagline.\n",
      "D: Wash your hair with an antifungal shampoo.\n",
      "\n",
      "Answer: B\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Get 1k Followers on Instagram\n",
      "A: Add a relevant, informative bio.\n",
      "B: Find strength in numbers.\n",
      "C: Understand how restrictive modifiers work.\n",
      "D: Write the two-column proof as an outline.\n",
      "\n",
      "Answer: A\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Fake Food Poisoning\n",
      "MCQ:\n",
      "A: Go to a historical preservation.\n",
      "B: Place time restrictions on impulsive thoughts.\n",
      "C: Decide on the background or the foreground.\n",
      "D: Invent a dicey dining situation.\n",
      "\n",
      "Answer:\n",
      "\n",
      "output: - Dicey dining situation.\n",
      "  - MCQ\n",
      "  \n",
      "  A: Go to a historical preservation.\n",
      "  B: Place time restrictions on impulsive thoughts.\n",
      "  C: Decide on the background or the foreground.\n",
      "  D: Invent a dicey dining situation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing queries:  15%|███▌                    | 3/20 [00:09<00:39,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "model_name: llama2:text\n",
      "prompt: \n",
      "You are answering a multiple choice question.\n",
      "Given four choices, you are to determine which step belongs in the tutorial.\n",
      "\n",
      "For example:\n",
      "Determine which step belongs in the tutorial of how to Send Money from India\n",
      "A: Have your forms reviewed if possible.\n",
      "B: Choose how the funds will be distributed.\n",
      "C: Develop a personal tagline.\n",
      "D: Wash your hair with an antifungal shampoo.\n",
      "\n",
      "Answer: B\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Get 1k Followers on Instagram\n",
      "A: Add a relevant, informative bio.\n",
      "B: Find strength in numbers.\n",
      "C: Understand how restrictive modifiers work.\n",
      "D: Write the two-column proof as an outline.\n",
      "\n",
      "Answer: A\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Prevent Toxic Shock Syndrome\n",
      "MCQ:\n",
      "A: Draw lines at the bottom loop and then they will look like feathers.\n",
      "B: Follow instructions carefully when using vaginal contraceptives.\n",
      "C: Spot test your blood on a dirty shirt to see how it will look.\n",
      "D: Place the wine glass upside down on a soft towel so that it can air dry.\n",
      "\n",
      "Answer:\n",
      "\n",
      "output: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing queries:  20%|████▊                   | 4/20 [00:09<00:25,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "model_name: llama2:text\n",
      "prompt: \n",
      "You are answering a multiple choice question.\n",
      "Given four choices, you are to determine which step belongs in the tutorial.\n",
      "\n",
      "For example:\n",
      "Determine which step belongs in the tutorial of how to Send Money from India\n",
      "A: Have your forms reviewed if possible.\n",
      "B: Choose how the funds will be distributed.\n",
      "C: Develop a personal tagline.\n",
      "D: Wash your hair with an antifungal shampoo.\n",
      "\n",
      "Answer: B\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Get 1k Followers on Instagram\n",
      "A: Add a relevant, informative bio.\n",
      "B: Find strength in numbers.\n",
      "C: Understand how restrictive modifiers work.\n",
      "D: Write the two-column proof as an outline.\n",
      "\n",
      "Answer: A\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Report a School for Discriminatory Discipline\n",
      "MCQ:\n",
      "A: Consider filing an institutional grievance.\n",
      "B: Double check all payment amounts.\n",
      "C: Copy and mail your form.\n",
      "D: Identify a suspected fraudulent mortgage.\n",
      "\n",
      "Answer:\n",
      "\n",
      "output: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing queries:  20%|████▊                   | 4/20 [00:09<00:39,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "model_name: llama2:text\n",
      "prompt: \n",
      "You are answering a multiple choice question.\n",
      "Given four choices, you are to determine which step belongs in the tutorial.\n",
      "\n",
      "For example:\n",
      "Determine which step belongs in the tutorial of how to Send Money from India\n",
      "A: Have your forms reviewed if possible.\n",
      "B: Choose how the funds will be distributed.\n",
      "C: Develop a personal tagline.\n",
      "D: Wash your hair with an antifungal shampoo.\n",
      "\n",
      "Answer: B\n",
      "\n",
      "Determine which step belongs in the tutorial of how to Get 1k Followers on Instagram\n",
      "A: Add a relevant, informative bio.\n",
      "B: Find strength in numbers.\n",
      "C: Understand how restrictive modifiers work.\n",
      "D: Write the two-column proof as an outline.\n",
      "\n",
      "Answer: A\n",
      "\n",
      "Determine which step belongs in the tutorial of how to List for Sale by Owner Using MLS Listing\n",
      "MCQ:\n",
      "A: Learning about more than.\n",
      "B: Know what a payment gateway is.\n",
      "C: Know what a finance charge is.\n",
      "D: Know what the Multiple Listing Service system is.\n",
      "\n",
      "Answer:\n",
      "\n",
      "output: \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m      1\u001b[0m simple_QA_chain \u001b[38;5;241m=\u001b[39m ChainManager()\n\u001b[1;32m      3\u001b[0m simple_QA_chain\u001b[38;5;241m.\u001b[39mprompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mYou are answering a multiple choice question.\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mGiven four choices, you are to determine which step belongs in the tutorial.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124mAnswer:\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m simple_QA_chain\u001b[38;5;241m.\u001b[39mrun_batch_query(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/kohjunkai/Desktop/without_classifier.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m simple_QA_chain\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/kohjunkai/Desktop/without_classifier.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[12], line 92\u001b[0m, in \u001b[0;36mChainManager.run_batch_query\u001b[0;34m(self, verbose, batch_size, output_file_name)\u001b[0m\n\u001b[1;32m     88\u001b[0m             num_retries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     89\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm(input_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing queries\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#                     result = self.run_single_query(item, model_name, verbose, output_file_name) \u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#                     result = self.run_single_self_review(item, model_name, verbose, output_file_name) \u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m                     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_without_classifier(item, model_name, verbose, output_file_name) \n\u001b[1;32m     93\u001b[0m                     results\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     94\u001b[0m                     num_retries\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[12], line 43\u001b[0m, in \u001b[0;36mChainManager.run_without_classifier\u001b[0;34m(self, inputs, model_name, verbose, output_file_name)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_string_to_buffer(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_string_to_buffer(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (output\u001b[38;5;241m.\u001b[39mstrip()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupper(), \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "simple_QA_chain = ChainManager()\n",
    "\n",
    "simple_QA_chain.prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are answering a multiple choice question.\n",
    "Given four choices, you are to determine which step belongs in the tutorial of how to {goal}\n",
    "MCQ:\n",
    "A: {step0}\n",
    "B: {step1}\n",
    "C: {step2}\n",
    "D: {step3}\n",
    "You are to provide a clear explanation for your choice.\n",
    "At the end of your explanation, explicitly state which step belongs in the tutorial.\n",
    "\"\"\")\n",
    "\n",
    "simple_QA_chain.run_batch_query(False, 10, \"/Users/kohjunkai/Desktop/without_classifier.txt\")\n",
    "simple_QA_chain.df.to_csv('/Users/kohjunkai/Desktop/without_classifier.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf78eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama2: 0.44857142857142857\n",
      "mistral: 0.5542857142857143\n",
      "orca-mini:7b: 0.32857142857142857\n",
      "qwen:7b: 0.48\n"
     ]
    }
   ],
   "source": [
    "simple_QA_chain.evaluate_order()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad06ff4",
   "metadata": {},
   "source": [
    "### Chain of thought  + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "221e3fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|█████████████████████| 350/350 [1:40:43<00:00, 17.27s/it]\n",
      "Processing queries: 100%|███████████████████████| 350/350 [47:26<00:00,  8.13s/it]\n",
      "Processing queries: 100%|█████████████████████| 350/350 [1:19:19<00:00, 13.60s/it]\n",
      "Processing queries: 100%|█████████████████████| 350/350 [1:30:03<00:00, 15.44s/it]\n"
     ]
    }
   ],
   "source": [
    "chain = ChainManager()\n",
    "\n",
    "chain.prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are answering a multiple choice question.\n",
    "Given four choices, you are to determine which step belongs in the tutorial of how to {goal}\n",
    "MCQ:\n",
    "A: {step0}\n",
    "B: {step1}\n",
    "C: {step2}\n",
    "D: {step3}\n",
    "You are to provide a clear explanation for your choice.\n",
    "At the end of your explanation, explicitly state which step belongs in the tutorial.\n",
    "\"\"\")\n",
    "\n",
    "chain.run_batch_query(False, 350, \"/Users/kohjunkai/Desktop/step_COT.txt\")\n",
    "chain.df.to_csv('/Users/kohjunkai/Desktop/step_COT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f12455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b63eea9",
   "metadata": {},
   "source": [
    "### Self Critique + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b096ad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|█████████████████████| 200/200 [1:55:34<00:00, 34.67s/it]\n",
      "Processing queries: 100%|█████████████████████| 200/200 [1:28:35<00:00, 26.58s/it]\n",
      "Processing queries: 100%|█████████████████████| 200/200 [1:25:33<00:00, 25.67s/it]\n",
      "Processing queries: 100%|█████████████████████| 200/200 [1:19:43<00:00, 23.92s/it]\n"
     ]
    }
   ],
   "source": [
    "info_gen_chain = ChainManager()\n",
    "\n",
    "info_gen_chain.prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are answering a multiple choice question.\n",
    "Given four choices, you are to determine which step belongs in the tutorial of how to {goal}\n",
    "MCQ:\n",
    "A: {step0}\n",
    "B: {step1}\n",
    "C: {step2}\n",
    "D: {step3}\n",
    "You are to provide a clear explanation for your choice.\n",
    "At the end of your explanation, explicitly state which step belongs in the tutorial.\n",
    "\"\"\")\n",
    "\n",
    "info_gen_chain.run_batch_query(False,200, \"/Users/kohjunkai/Desktop/step_self_critque.txt\")\n",
    "info_gen_chain.df.to_csv('/Users/kohjunkai/Desktop/step_self_critque.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f7b138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama2: 0.6\n",
      "mistral: 0.5\n",
      "orca-mini:7b: 0.4\n",
      "qwen:7b: 0.5\n"
     ]
    }
   ],
   "source": [
    "pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95376a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
